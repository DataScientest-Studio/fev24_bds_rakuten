{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io, color, feature, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import load\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/05 16:59:09 INFO mlflow.tracking.fluent: Experiment with name 'features RF' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"../../mlruns\")\n",
    "mlflow.set_experiment(\"features RF\")\n",
    "mlflow.sklearn.autolog(log_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins\n",
    "images_path = \"/Users/jeremyrava/Documents/01 - Projets/fev24_bds_rakuten/data/raw/images/image_train\"\n",
    "X_csv_path = \"/Users/jeremyrava/Documents/01 - Projets/fev24_bds_rakuten/data/processed/X_train_update (komla).csv\"\n",
    "y_csv_path = \"/Users/jeremyrava/Documents/01 - Projets/fev24_bds_rakuten/data/processed/Y_train_CVw08PX (komla).csv\"\n",
    "\n",
    "# Chargement des données\n",
    "X_df = pd.read_csv(X_csv_path)\n",
    "y_df = pd.read_csv(y_csv_path)\n",
    "\n",
    "# Réduire les données aux 5000 premières lignes\n",
    "sample_X = X_df\n",
    "sample_y = y_df[\"prdtypecode\"]\n",
    "\n",
    "# Ajout du chemin complet des images dans sample_X\n",
    "sample_X[\"image_path\"] = sample_X.apply(\n",
    "    lambda row: os.path.join(\n",
    "        images_path, f\"image_{row.imageid}_product_{row.productid}.jpg\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 16:59:16.298448: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-05-05 16:59:16.298469: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-05 16:59:16.298475: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-05 16:59:16.298704: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-05 16:59:16.298717: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Configuration pour la vectorisation du texte\n",
    "max_tokens = 10000\n",
    "output_sequence_length = 250\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=output_sequence_length,\n",
    ")\n",
    "vectorize_layer.adapt(sample_X[\"description\"].fillna(\"\"))\n",
    "\n",
    "# Appliquer la vectorisation au texte pour obtenir les vecteurs\n",
    "X_text_vectors = vectorize_layer(sample_X[\"description\"].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les caractéristiques HOG d'une image\n",
    "def extract_hog_features(image_path):\n",
    "    image = io.imread(image_path)\n",
    "    image_gray = color.rgb2gray(image)\n",
    "    image_resized = transform.resize(image_gray, (128, 64), anti_aliasing=True)\n",
    "    hog_features = feature.hog(\n",
    "        image_resized, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=False\n",
    "    )\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des caractéristiques HOG pour les images\n",
    "features_images = np.array(\n",
    "    [extract_hog_features(path) for path in sample_X[\"image_path\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rééquilibrage des classes avec RandomOverSampler pour les deux types de données\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled_images, y_resampled_images = ros.fit_resample(features_images, sample_y)\n",
    "X_resampled_text, y_resampled_text = ros.fit_resample(X_text_vectors, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données rééquilibrées en ensembles d'entraînement et de test pour les images et le texte\n",
    "X_train_images, X_test_images, y_train_images, y_test_images = train_test_split(\n",
    "    X_resampled_images, y_resampled_images, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
    "    X_resampled_text, y_resampled_text, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation des caractéristiques image et texte (sans conversion à dense si déjà en numpy array)\n",
    "X_train_combined = np.hstack((X_train_images, X_train_text))\n",
    "X_test_combined = np.hstack((X_test_images, X_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: 3ed6f6fd6971442db10cff63789ff786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "2024/05/05 17:14:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "# Utiliser un modèle unique pour la classification sur les caractéristiques combinées\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "combined_model = RandomForestClassifier(random_state=42)\n",
    "with mlflow.start_run() as run:\n",
    "    print(\"Run id:\", run.info.run_id)\n",
    "    combined_model.fit(\n",
    "        X_train_combined, y_train_images\n",
    "    )  # y_train_images doit être identique à y_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = combined_model.predict(X_test_combined)\n",
    "report = classification_report(y_test_images, y_pred_test, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report.to_csv(\"report_Features_RF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features Model Accuracy: 0.9251743817374762\n",
      "Classification Report for Combined Features Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.93      0.95      0.94       120\n",
      "          40       0.95      0.98      0.97       113\n",
      "          50       0.96      1.00      0.98       129\n",
      "          60       0.95      1.00      0.97       112\n",
      "        1140       0.95      0.93      0.94       117\n",
      "        1160       0.97      0.93      0.95       122\n",
      "        1180       1.00      1.00      1.00       125\n",
      "        1280       0.89      0.84      0.86       128\n",
      "        1281       0.98      1.00      0.99       127\n",
      "        1300       0.88      0.83      0.85       109\n",
      "        1301       1.00      1.00      1.00       123\n",
      "        1302       0.92      0.94      0.93       122\n",
      "        1320       0.97      0.98      0.97       113\n",
      "        1560       0.79      0.73      0.76       119\n",
      "        1920       0.90      0.95      0.93       118\n",
      "        1940       0.98      1.00      0.99       114\n",
      "        2060       0.81      0.81      0.81       122\n",
      "        2220       0.99      1.00      1.00       111\n",
      "        2280       0.87      0.91      0.89       113\n",
      "        2403       0.80      0.89      0.84       116\n",
      "        2462       0.97      1.00      0.99       108\n",
      "        2522       0.85      0.83      0.84       109\n",
      "        2582       0.99      0.98      0.99       103\n",
      "        2583       0.71      0.53      0.61       115\n",
      "        2585       0.98      0.96      0.97       111\n",
      "        2705       0.96      0.99      0.97       113\n",
      "        2905       0.95      1.00      0.98       122\n",
      "\n",
      "    accuracy                           0.93      3154\n",
      "   macro avg       0.92      0.93      0.92      3154\n",
      "weighted avg       0.92      0.93      0.92      3154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction et évaluation\n",
    "y_pred_combined = combined_model.predict(X_test_combined)\n",
    "print(\n",
    "    \"Combined Features Model Accuracy:\", accuracy_score(y_test_images, y_pred_combined)\n",
    ")\n",
    "print(\"Classification Report for Combined Features Model:\")\n",
    "print(classification_report(y_test_images, y_pred_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
