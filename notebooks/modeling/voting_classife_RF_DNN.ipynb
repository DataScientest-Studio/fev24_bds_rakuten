{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, string\n",
    "from skimage import io, color, feature, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"../../mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins\n",
    "images_path = \"/Users/jeremyrava/Documents/01 - Projets/fev24_bds_rakuten/data/raw/images/image_train\"\n",
    "X_csv_path = (\n",
    "    \"/Users/jeremyrava/Documents/01 - Projets/fev24_bds_rakuten/data/raw/x_train.csv\"\n",
    ")\n",
    "y_csv_path = (\n",
    "    \"/Users/jeremyrava/Documents/01 - Projets/fev24_bds_rakuten/data/raw/y_train.csv\"\n",
    ")\n",
    "\n",
    "# Chargement des données\n",
    "X_df = pd.read_csv(X_csv_path, index_col=0)\n",
    "y_df = pd.read_csv(y_csv_path, index_col=0)\n",
    "\n",
    "X_df[\"text\"] = np.where(\n",
    "    X_df[\"description\"].isna(),\n",
    "    X_df[\"designation\"].astype(str),\n",
    "    X_df[\"designation\"].astype(str) + \" \" + X_df[\"description\"].astype(str),\n",
    ")\n",
    "\n",
    "# Réduire les données aux 5000 premières lignes\n",
    "sample_X = X_df\n",
    "target = y_df[\"prdtypecode\"]\n",
    "\n",
    "# Ajout du chemin complet des images dans sample_X\n",
    "sample_X[\"image_path\"] = sample_X.apply(\n",
    "    lambda row: os.path.join(\n",
    "        images_path, f\"image_{row.imageid}_product_{row.productid}.jpg\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data = sample_X[[\"text\", \"image_path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 09:54:34.804363: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-05-10 09:54:34.804386: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-10 09:54:34.804393: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-10 09:54:34.804616: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-10 09:54:34.804636: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_data):\n",
    "    \"\"\"\n",
    "    Custom standardization function for text data.\n",
    "\n",
    "    Args:\n",
    "        input_data: The input text data.\n",
    "\n",
    "    Returns:\n",
    "        The standardized text data.\n",
    "    \"\"\"\n",
    "    # Decode the input HTML using UTF-8 encoding.\n",
    "    decoded_html = tf.strings.unicode_decode(input_data, \"UTF-8\")\n",
    "\n",
    "    # Encode the decoded HTML back into HTML for further processing.\n",
    "    encoded_html = tf.strings.unicode_encode(decoded_html, \"UTF-8\")\n",
    "\n",
    "    # Strip all HTML tags from the input data using a regular expression replace operation.\n",
    "    stripped_html = tf.strings.regex_replace(encoded_html, \"<[^>]*>\", \" \")\n",
    "\n",
    "    # Convert the input text to lowercase for consistency.\n",
    "    lowercase = tf.strings.lower(stripped_html)\n",
    "\n",
    "    # Remove extra whitespace by replacing one or more spaces with a single space.\n",
    "    cleaned_input_data = tf.strings.regex_replace(lowercase, r\"\\s+\", \" \")\n",
    "\n",
    "    # Replace punctuation characters with empty strings (i.e., remove them).\n",
    "    return tf.strings.regex_replace(\n",
    "        cleaned_input_data, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=100000,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=250,\n",
    ")\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "vectorize_layer.adapt(sample_X[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les caractéristiques HOG d'une image\n",
    "def extract_hog_features(image_path):\n",
    "    image = io.imread(image_path)\n",
    "    image_gray = color.rgb2gray(image)\n",
    "    image_resized = transform.resize(image_gray, (128, 64), anti_aliasing=True)\n",
    "    hog_features = feature.hog(\n",
    "        image_resized, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=False\n",
    "    )\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_text vectorised\n",
      "X_test_text vectorised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ee8c5ca0904971bedf1f2cff3694ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c649a0653cd4bf8b663d3c5a2e15969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Appliquer la vectorisation au texte pour obtenir les vecteurs\n",
    "X_train_text_vectors = vectorize_layer(X_train[\"text\"])\n",
    "print(\"X_train_text vectorised\")\n",
    "X_test_text_vectors = vectorize_layer(X_test[\"text\"])\n",
    "print(\"X_test_text vectorised\")\n",
    "\n",
    "# Préparation des caractéristiques HOG pour les images\n",
    "X_train_features_images = np.array(\n",
    "    [extract_hog_features(path) for path in tqdm(X_train[\"image_path\"])]\n",
    ")\n",
    "X_test_features_images = np.array(\n",
    "    [extract_hog_features(path) for path in tqdm(X_test[\"image_path\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(log_datasets=False, disable=True)  # pour ne pas log\n",
    "\n",
    "reequilibrage = False\n",
    "\n",
    "if reequilibrage:\n",
    "    # Rééquilibrage des classes avec RandomOverSampler pour les deux types de données\n",
    "    # ros = RandomOverSampler(random_state=42)\n",
    "    ros = SMOTE(random_state=42)\n",
    "    X_train_resampled_text, y_resampled_text = ros.fit_resample(\n",
    "        X_train_text_vectors, y_train\n",
    "    )\n",
    "    X_train_resampled_images, y_resampled_images = ros.fit_resample(\n",
    "        X_train_features_images, y_train\n",
    "    )\n",
    "else:\n",
    "    X_train_resampled_text = X_train_text_vectors\n",
    "    X_train_resampled_images = X_train_features_images\n",
    "    y_resampled_text = y_train\n",
    "    y_resampled_images = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation des caractéristiques image et texte (sans conversion à dense si déjà en numpy array)\n",
    "X_train_combined = np.hstack((X_train_resampled_images, X_train_resampled_text))\n",
    "X_test_combined = np.hstack((X_test_features_images, X_test_text_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: 7436e7b427ac4caaae6d76fa5df756b3\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.380 total time=  11.6s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.384 total time=  11.6s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.381 total time=  11.6s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.377 total time=  11.8s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=2, n_estimators=10;, score=0.383 total time=  12.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.377 total time=  10.2s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.379 total time=  10.2s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.383 total time=   9.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.377 total time=   9.9s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=5, n_estimators=10;, score=0.376 total time=  10.7s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=2, n_estimators=50;, score=0.425 total time=  52.9s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=2, n_estimators=50;, score=0.437 total time=  53.2s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=2, n_estimators=50;, score=0.431 total time=  53.2s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=2, n_estimators=50;, score=0.436 total time=  53.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=2, n_estimators=50;, score=0.427 total time=  53.9s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=5, n_estimators=50;, score=0.424 total time=  49.8s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=5, n_estimators=50;, score=0.426 total time=  48.5s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=5, n_estimators=50;, score=0.435 total time=  48.5s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=5, n_estimators=50;, score=0.428 total time=  48.3s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=5, n_estimators=50;, score=0.422 total time=  48.4s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.436 total time= 1.7min\n",
      "[CV 2/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.435 total time= 1.7min\n",
      "[CV 1/5] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.378 total time=   9.6s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.375 total time=   9.6s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.380 total time=   9.3s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.444 total time= 1.7min\n",
      "[CV 4/5] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.376 total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.448 total time= 1.7min\n",
      "[CV 4/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.438 total time= 1.7min\n",
      "[CV 5/5] END max_depth=None, min_samples_split=10, n_estimators=10;, score=0.378 total time=   9.4s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.434 total time= 1.6min\n",
      "[CV 2/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.431 total time= 1.6min\n",
      "[CV 1/5] END max_depth=None, min_samples_split=10, n_estimators=50;, score=0.417 total time=  46.4s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=10, n_estimators=50;, score=0.416 total time=  47.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=10, n_estimators=50;, score=0.424 total time=  47.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=10, n_estimators=50;, score=0.425 total time=  46.1s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=10, n_estimators=50;, score=0.417 total time=  47.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.443 total time= 1.6min\n",
      "[CV 4/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.430 total time= 1.5min\n",
      "[CV 5/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.435 total time= 1.5min\n",
      "[CV 1/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.426 total time= 1.4min\n",
      "[CV 2/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.423 total time= 1.4min\n",
      "[CV 3/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.430 total time= 1.3min\n",
      "[CV 4/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.426 total time= 1.3min\n",
      "[CV 5/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.429 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "2024/05/10 10:11:21 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/anaconda3/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/05/10 10:11:24 INFO mlflow.sklearn.utils: Logging the 5 best runs, 4 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.440271164327161\n"
     ]
    }
   ],
   "source": [
    "# Utiliser un modèle unique pour la classification sur les caractéristiques combinées\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "combined_model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"max_depth\": [None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    combined_model, param_grid, cv=5, scoring=\"f1_weighted\", verbose=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"features RF\")\n",
    "mlflow.sklearn.autolog(log_datasets=False, disable=False)\n",
    "description = \"SMOTE(random_state=42) sur la totlité de X_train (sans diminuer les ecarts des targets)\"\n",
    "with mlflow.start_run(description=description) as run:\n",
    "    print(\"Run id:\", run.info.run_id)\n",
    "    grid_search.fit(\n",
    "        X_train_combined, y_resampled_text\n",
    "    )  # y_train_images doit être identique à y_train_text\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_params)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features Model Accuracy: 0.4774493641073952\n",
      "Classification Report for Combined Features Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.41      0.48      0.44       612\n",
      "          40       0.50      0.37      0.42       521\n",
      "          50       0.85      0.14      0.24       357\n",
      "          60       0.60      0.33      0.42       161\n",
      "        1140       0.44      0.37      0.40       539\n",
      "        1160       0.72      0.77      0.74       786\n",
      "        1180       0.76      0.09      0.16       146\n",
      "        1280       0.26      0.17      0.21       961\n",
      "        1281       0.38      0.03      0.06       424\n",
      "        1300       0.39      0.44      0.41       974\n",
      "        1301       0.92      0.29      0.44       169\n",
      "        1302       0.59      0.15      0.23       507\n",
      "        1320       0.53      0.17      0.26       672\n",
      "        1560       0.35      0.43      0.38      1013\n",
      "        1920       0.69      0.68      0.68       841\n",
      "        1940       0.81      0.09      0.17       137\n",
      "        2060       0.32      0.49      0.39      1029\n",
      "        2220       1.00      0.05      0.10       170\n",
      "        2280       0.46      0.72      0.56       942\n",
      "        2403       0.37      0.63      0.47       986\n",
      "        2462       0.44      0.16      0.24       306\n",
      "        2522       0.64      0.56      0.60       991\n",
      "        2582       0.71      0.15      0.25       462\n",
      "        2583       0.49      0.84      0.62      2047\n",
      "        2585       0.85      0.20      0.33       525\n",
      "        2705       0.65      0.72      0.68       517\n",
      "        2905       0.88      0.89      0.89       189\n",
      "\n",
      "    accuracy                           0.48     16984\n",
      "   macro avg       0.59      0.39      0.40     16984\n",
      "weighted avg       0.52      0.48      0.45     16984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modele_selected = \"7436e7b427ac4caaae6d76fa5df756b3\"  # ID du run du modèle sélectionné\n",
    "logged_model = f\"runs:/{modele_selected}/best_estimator\"  # choisir \"/model\" pour model standard ou \"/best_estimator\" pour un GridSearchCV\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Prédiction et évaluation\n",
    "y_pred_combined = loaded_model.predict(X_test_combined)\n",
    "print(\"Combined Features Model Accuracy:\", accuracy_score(y_test, y_pred_combined))\n",
    "print(\"Classification Report for Combined Features Model:\")\n",
    "print(classification_report(y_test, y_pred_combined))\n",
    "report = classification_report(y_test, y_pred_combined, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report.to_csv(f\"report_Features_RF_{modele_selected}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
